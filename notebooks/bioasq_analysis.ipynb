{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "tf.test.is_gpu_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from biomedical_qa import util\n",
    "\n",
    "from biomedical_qa.inference.inference import Inferrer, get_model_and_session\n",
    "from biomedical_qa.sampling.bioasq import BioAsqSampler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]= \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_model_and_session' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-30f7e0c2db25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#\"../model_checkpoints/simple_pointer_with_chars/bioasq_finetune_dr05_sigmoid_bioasqtrainer_ckptits200/config.pickle\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model_and_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONFIG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"cpu:0\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0minferrer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInferrer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_model_and_session' is not defined"
     ]
    }
   ],
   "source": [
    "CONFIG = \"./results/config.pickle\"\n",
    "#\"../model_checkpoints/simple_pointer_with_chars/bioasq_finetune_dr05_sigmoid_bioasqtrainer_ckptits200/config.pickle\"\n",
    "\n",
    "model, sess = get_model_and_session(CONFIG, [\"cpu:0\"])\n",
    "inferrer = Inferrer(model, sess, beam_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = inferrer.model.embedder.vocab\n",
    "rev_vocab = [\"\"] * len(vocab)\n",
    "for w, i in vocab.items():\n",
    "    rev_vocab[i] = w\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampler = BioAsqSampler(\"../data/bioasq\", [\"dev.json\"], 16, vocab=vocab, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = inferrer.get_predictions(sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factoid Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "factoid_predictions = {id: p for id, p in predictions.items() if p.question.q_type == \"factoid\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for prediction in factoid_predictions.values():\n",
    "    \n",
    "    print_prediction(prediction, rev_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_correct_lenient(prediction):\n",
    "    correct_answers = maybe_flatten_list(prediction.question.question_json[\"original_answers\"])\n",
    "    for correct_answer in correct_answers:\n",
    "        for predicted_answer in prediction.answer_strings:\n",
    "            if correct_answer.lower().strip() == predicted_answer.lower().strip():\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correct_predictions = {id: p for id, p in factoid_predictions.items() if is_correct_lenient(p)}\n",
    "incorrect_predictions = {id: p for id, p in factoid_predictions.items() if not is_correct_lenient(p)}\n",
    "\n",
    "print(\"Correct: %d, Incorrect: %d\" % (len(correct_predictions), len(incorrect_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pointer Visualization (Incorrect Answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for prediction in incorrect_predictions.values():\n",
    "    print_prediction(prediction, rev_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = incorrect_predictions[\"54fc99f36ad7dcbc12000004\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_prediction(prediction, rev_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokens = get_tokens(prediction, rev_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correct_tokens = find_correct_tokens(prediction.question)\n",
    "\n",
    "text_heatmap(tokens, prediction.prediction.start_probs, correct_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "#start_token_mask = np.zeros(len(tokens), dtype=np.bool)\n",
    "#start_token_mask[prediction.starts[0]] = True\n",
    "\n",
    "#text_heatmap(tokens, prediction.end_scores[0], start_token_mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3.6 (biotransfer)",
   "language": "python",
   "name": "biotransfer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
